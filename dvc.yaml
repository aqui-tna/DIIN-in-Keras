stages:
  step0_data-preprocessing:
    cmd: python preprocess.py --p 32 --h 32 --chars_per_word 16 --save_dir data/ --dataset
      snli --word_vec_save_path data/word-vectors.npy
    params:
    - p
    - h
    - chars_per_word
    - save_dir
    - dataset
    - word_vec_save_path
    deps:
    - preprocess.py
  step1_trainning:
    cmd: python train.py --batch_size 70 --eval_interval 500 --train_word_embeddings
      --char_embed_size 8 --char_conv_filters 100 --char_conv_kernel 5 --dropout_initial_keep_rate
      1. --dropout_decay_rate 0.977 --dropout_decay_interval 10000 --first_scale_down_ratio
      0.3 --transition_scale_down_ratio 0.5 --growth_rate 20 --layers_per_dense_block
      8 --dense_blocks 3 --labels 3 --load_dir ./data --models_dir ./models/ --logdir
      ./logs --word_vec_path ./data/word-vectors.npy
    params:
    - batch_size
    - eval_interval
    - char_embed_size
    - char_conv_filters
    - char_conv_kernel
    - dropout_initial_keep_rate
    - dropout_decay_rate
    - dropout_decay_interval
    - l2_full_step
    - l2_full_ratio
    - l2_diference_penalty
    - first_scale_down_ratio
    - transition_scale_down_ratio
    - growth_rate
    - layers_per_dense_block
    - dense_blocks
    - labels
    - load_dir
    - models_dir
    - logdir
    - word_vec_path
    deps:
    - train.py
